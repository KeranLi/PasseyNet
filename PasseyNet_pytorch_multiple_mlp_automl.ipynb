{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb34e14-49ee-47c9-b10c-e5e55b4b32b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ray\n",
    "from ray import tune\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error \n",
    "from sklearn.model_selection import KFold\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dab87b-45ee-47d9-aa5e-1f767de59f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading training set into dataframe\n",
    "df = pd.read_csv('./data/TOC_WF_LMX_2K.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Depth/Thickness(m)')\n",
    "df = df.drop(columns='Journal')\n",
    "df = df.drop(columns='Author')\n",
    "df = df.drop(columns='Well')\n",
    "df = df.drop(columns='Area')\n",
    "df = df.drop(columns='DOI1')\n",
    "df = df.drop(columns='DOI2')\n",
    "df = df.drop(columns='Unnamed: 11')\n",
    "df = df.drop(columns='Unnamed: 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b94cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example, taking TOC as label to predict\n",
    "label_data = df['TOC(%)']\n",
    "train_data = df.drop('TOC(%)', axis=1) # we don't need it in this project\n",
    "label_data.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3e52b-c81e-4158-85fd-22df0d1edb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to min-max normalize\n",
    "def normalize(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with normalized specified features\n",
    "    \"\"\"\n",
    "    result = df.copy() # do not touch the original df\n",
    "    for feature_name in cols:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        if max_value > min_value:\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba56068-6779-492c-8e6d-433086081a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalizing dataset\n",
    "new_train = normalize(train_data,train_data.columns)\n",
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065e924-5158-48e4-88c2-177475cadae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_data.isnull().values.any()\n",
    "new_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d4656-eb84-49ff-8693-b471ddfd8ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test Nan and fill with mean\n",
    "for column in list(new_train.columns[ new_train.isnull().sum() > 0]):\n",
    "    mean_val = new_train[column].mean()\n",
    "    new_train[column].fillna(mean_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516439b-836c-4fc6-8764-e2e38ab75597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training = np.array(new_train)\n",
    "labeling = np.array(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298a7e4-69f1-4b70-ab4d-95faf37ff799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training = torch.tensor(training, dtype=torch.float32)\n",
    "labeling = torch.tensor(labeling, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1dbdb8-33fa-4d6c-8852-ae9ac4047f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labeling.shape, training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37867f50-f9e6-4d88-aeba-bc82581b43dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b318e2-6a0c-40ed-ad92-db866ec53336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.half_attenuate import HiddenSizesGenerator\n",
    "\n",
    "def get_hidden_sizes(input_size):\n",
    "\n",
    "    # Define the half-attenuation law of the neuron size\n",
    "\n",
    "    hidden_sizes = []\n",
    "    size = input_size\n",
    "    while size > 16:\n",
    "        hidden_sizes.append(size)\n",
    "        size = size // 2\n",
    "    return hidden_sizes\n",
    "\n",
    "class WellLogNet(nn.Module):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fix the hyper-paremeters in the input and output layers\n",
    "        \n",
    "        if not isinstance(hyperparams, dict):\n",
    "            hyperparams = {}\n",
    "\n",
    "        self.input_dim = hyperparams[\"input_dim\"]\n",
    "        self.output_dim = hyperparams[\"output_dim\"]\n",
    "\n",
    "        layers = []\n",
    "        in_size = hyperparams[\"input_dim\"]\n",
    "        out_size = hyperparams[\"output_dim\"]\n",
    "        sizes = get_hidden_sizes(hyperparams[\"hidden_sizes\"])\n",
    "        \n",
    "        for i, size in enumerate(sizes[:-1]):\n",
    "            layers.append(nn.Linear(in_size, size))\n",
    "            in_size = size\n",
    "        \n",
    "        layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def get_input_dim(self):\n",
    "        return self.input_dim\n",
    "    \n",
    "    def get_output_dim(self):\n",
    "        return self.output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Here, we use relu function to activate except for the last layer\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "class RONet(nn.Module):\n",
    "    def __init__(self, hyperparams={}):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fix the hyper-paremeters in the input and output layers\n",
    "        \n",
    "        if not isinstance(hyperparams, dict):\n",
    "            hyperparams = {}\n",
    "        \n",
    "        self.input_dim = hyperparams[\"input_dim\"]\n",
    "        self.output_dim = hyperparams[\"output_dim\"]\n",
    "\n",
    "        layers = []\n",
    "        in_size = hyperparams[\"input_dim\"]\n",
    "        out_size = hyperparams[\"output_dim\"]\n",
    "        sizes = get_hidden_sizes(hyperparams[\"hidden_sizes\"])\n",
    "\n",
    "        for i, size in enumerate(sizes[:-1]):\n",
    "            layers.append(nn.Linear(in_size, size))\n",
    "            in_size = size\n",
    "\n",
    "        layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Here, we use relu function to activate except for the last layer\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layers[-1](x)\n",
    "    \n",
    "class BiasNet(nn.Module):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fix the hyper-paremeters in the input and output layers\n",
    "        \n",
    "        if not isinstance(hyperparams, dict):\n",
    "            hyperparams = {}\n",
    "        \n",
    "        self.input_dim = hyperparams[\"input_dim\"]\n",
    "        self.output_dim = hyperparams[\"output_dim\"]\n",
    "        \n",
    "        layers = []\n",
    "        in_size = hyperparams[\"input_dim\"]\n",
    "        out_size = hyperparams[\"output_dim\"]\n",
    "        sizes = get_hidden_sizes(hyperparams[\"hidden_sizes\"])\n",
    "\n",
    "        for i, size in enumerate(sizes[:-1]):\n",
    "            layers.append(nn.Linear(in_size, size))\n",
    "            in_size = size\n",
    "        \n",
    "        layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Here, we use relu function to activate except for the last layer\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "class PasseyNet(nn.Module):\n",
    "    def __init__(self, well_log_net, ro_net, bias_net):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 获取子网络的输入输出维度\n",
    "        self.well_log_input_dim = well_log_net.input_dim\n",
    "        self.well_log_output_dim = well_log_net.output_dim\n",
    "        \n",
    "        self.ro_input_dim = ro_net.input_dim\n",
    "        self.ro_output_dim = ro_net.output_dim\n",
    "        \n",
    "        self.bias_input_dim = bias_net.input_dim\n",
    "        self.bias_output_dim = bias_net.output_dim\n",
    "\n",
    "        # 网络层\n",
    "        self.well_log_net = well_log_net\n",
    "        self.ro_net = ro_net\n",
    "        self.bias_net = bias_net\n",
    "        \n",
    "        # 输入输出维度\n",
    "        self.input_dim = self.well_log_input_dim\n",
    "        self.output_dim = self.bias_output_dim \n",
    "\n",
    "    def forward(self, x):\n",
    "        well_log_matrix = self.well_log_net(x)\n",
    "        ro_matrix = self.ro_net(x)\n",
    "        bias_matrix = self.bias_net(x)\n",
    "        \n",
    "        output = torch.matmul(torch.matmul(x, well_log_matrix.T), \n",
    "                              torch.pow(10.0, ro_matrix)) + bias_matrix\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters for search in the Net \n",
    "config = {\n",
    "  \"well_log_net\": {\n",
    "      \"input_dim\": 3,\n",
    "     \"hidden_sizes\": tune.choice([256, 512, 1024]),\n",
    "     \"output_dim\": 3 \n",
    "  },\n",
    "  \n",
    "  \"ro_net\": {\n",
    "      \"input_dim\": 3,\n",
    "     \"hidden_sizes\": tune.choice([256, 512, 1024]),\n",
    "     \"output_dim\": 1\n",
    "  },\n",
    "  \n",
    "  \"bias_net\": {\n",
    "      \"input_dim\": 3,\n",
    "     \"hidden_sizes\": tune.choice([256, 512, 1024]),\n",
    "     \"output_dim\": 1\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Define the NAS by ray\n",
    "def train_model(config):\n",
    "    \n",
    "    # Get config for each subnetwork\n",
    "    well_log_config = config[\"well_log_net\"]\n",
    "    ro_config = config[\"ro_net\"] \n",
    "    bias_config = config[\"bias_net\"]\n",
    "    \n",
    "    # Initialize subnetworks\n",
    "    well_log_net = WellLogNet(well_log_config)\n",
    "    ro_net = RONet(ro_config)\n",
    "    bias_net = BiasNet(bias_config) \n",
    "\n",
    "    # Initialize PasseyNet\n",
    "    model = PasseyNet(well_log_net, ro_net, bias_net)\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    x = training.to(device)\n",
    "    y = labeling.to(device)\n",
    "\n",
    "    # Initializing optimizer and loss functions\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Store loss、mae、mse、R2、mape\n",
    "    loss_list = []\n",
    "    mae_list = []\n",
    "    mse_list = []\n",
    "    r2_list = []\n",
    "    r2_adjust_list = []\n",
    "    mape_list = []\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42) # 5-fold\n",
    "\n",
    "        for fold ,(train_idx, val_idx) in enumerate(kf.split(x)):\n",
    "\n",
    "            # Dividing training and validating datasets\n",
    "            train_x, train_y = x[train_idx], y[train_idx]\n",
    "            val_x, val_y = x[val_idx], y[val_idx]\n",
    "\n",
    "            for epoch in range(100):\n",
    "\n",
    "                output = model(train_x) # Training\n",
    "                output = output.cpu() # Return output to CPU\n",
    "                label = train_y.cpu() # Return label to CPU\n",
    "                \n",
    "                loss = criterion(output, label)\n",
    "                optimizer.zero_grad()   \n",
    "                loss.backward()        \n",
    "                optimizer.step()\n",
    "\n",
    "                # Validating\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(val_x)\n",
    "                    val_output = val_output.cpu()\n",
    "                    val_y = val_y.cpu()\n",
    "                    val_loss = criterion(val_output, val_y)\n",
    "\n",
    "                    val_pred = val_output.detach().numpy()\n",
    "                    val_true = val_y.detach().numpy()\n",
    "\n",
    "                    val_mae = mean_absolute_error(val_true, val_pred)\n",
    "                    val_mse = mean_squared_error(val_true, val_pred)\n",
    "\n",
    "                    val_r2 = r2_score(val_true, val_pred)\n",
    "                    val_mape = mean_absolute_percentage_error(val_true, val_pred)\n",
    "\n",
    "                    val_adjust_r2 = 1-((1-val_r2)*(len(val_x)-1))/(len(val_x)-6-1)\n",
    "                    \n",
    "                    # 打印结果  \n",
    "                    # print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}, R2: {val_r2:.4f}, MAE: {val_mae:.4f}, MSE: {val_mse:.4f}, MAPE: {val_mape:.4f}')\n",
    "            \n",
    "                # 存储loss、mae和mse\n",
    "                loss_list.append(val_loss.item())\n",
    "                mae_list.append(val_mae)\n",
    "                mse_list.append(val_mse)\n",
    "                r2_list.append(val_r2)\n",
    "                r2_adjust_list.append(val_adjust_r2)\n",
    "                mae_list.append(val_mape)\n",
    "            \n",
    "            # Plot the 5-fold training results        \n",
    "            plt.plot(loss_list)\n",
    "            plt.title('Five-Fold Loss Curve')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "\n",
    "            # 绘制MAE、MSE、MAPE curves\n",
    "            plt.plot(mae_list, label='MAE')\n",
    "            plt.plot(mse_list, label='MSE')\n",
    "            plt.plot(mae_list, label='MAE')\n",
    "            plt.title('MAE, MSE, MAPE Curve')  \n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot R2、R2_adjust curves\n",
    "            plt.plot(r2_list, label='R2')\n",
    "            plt.plot(r2_adjust_list, label='R2_adjust')\n",
    "            plt.title('R2 & Adjusted R2 Curve')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "    score = -val_mse(model)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Run tune\n",
    "ray.shutdown()\n",
    "ray.init(num_gpus=1)\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    stop={\"episode_reward_mean\": 0.005},\n",
    "    config=config,\n",
    "    num_samples=10, # Number of tray\n",
    "    metric=\"score\",\n",
    "    mode=\"max\",\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    fail_fast=\"raise\"  \n",
    ")\n",
    "\n",
    "# Best config   \n",
    "best_config = analysis.get_best_config()\n",
    "\n",
    "# Generate model by the best config\n",
    "well_log_net = WellLogNet(best_config[\"well_log_net\"])\n",
    "ro_net = RONet(best_config[\"ro_net\"])\n",
    "bias_net = BiasNet(best_config[\"bias_net\"])\n",
    "best_model = PasseyNet(well_log_net, ro_net, bias_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training set into dataframe\n",
    "test_df = pd.read_csv('./data/TOC_WF_LMX.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns='Depth/Thickness(m)')\n",
    "test_df = test_df.drop(columns='Journal')\n",
    "test_df = test_df.drop(columns='Author')\n",
    "test_df = test_df.drop(columns='Well')\n",
    "test_df = test_df.drop(columns='Area')\n",
    "test_df = test_df.drop(columns='DOI1')\n",
    "test_df = test_df.drop(columns='DOI2')\n",
    "test_df = test_df.drop(columns='Unnamed: 11')\n",
    "test_df = test_df.drop(columns='Unnamed: 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09aef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_last_30 = test_df.tail(30)\n",
    "test_df_last_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ec004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example, taking TOC as label to predict\n",
    "test_label = test_df_last_30['TOC(%)']\n",
    "test_train = test_df_last_30.drop('TOC(%)', axis=1) # we don't need it in this project\n",
    "test_label.shape, test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train = test_train.drop(columns='井名')\n",
    "# test_train = test_train.drop(columns='Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b135ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing dataset\n",
    "normalized_test_train = normalize(test_train, test_train.columns)\n",
    "normalized_test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41110f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Nan and fill with mean\n",
    "for column in list(normalized_test_train.columns[ normalized_test_train.isnull().sum() > 0]):\n",
    "    mean_val = normalized_test_train[column].mean()\n",
    "    normalized_test_train[column].fillna(mean_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ec0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要传入Tensor \n",
    "X_test = normalized_test_train.values # 转为numpy数组\n",
    "X_test = torch.Tensor(X_test).to(device) # 转为Tensor\n",
    "\n",
    "\n",
    "# 切换到训练模式\n",
    "model.train() \n",
    "\n",
    "# 预测值 \n",
    "y_pred = model(X_test)\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "# 真实值\n",
    "y_true = test_label \n",
    "\n",
    "# 残差 \n",
    "y_true = y_true.ravel()  \n",
    "y_pred = y_pred.ravel()\n",
    "resid = y_true - y_pred\n",
    "\n",
    "# 绘图\n",
    "plt.hist(resid, bins=20)\n",
    "plt.title('Residuals Histogram')\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 均值和标准差\n",
    "mean = resid.mean()\n",
    "stddev = resid.std()\n",
    "\n",
    "# 绘制竖直线\n",
    "plt.axvline(mean, color='r')\n",
    "plt.axvline(mean + 2*stddev, color='r', linestyle='--')\n",
    "plt.axvline(mean - 2*stddev, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测值实际值差距图\n",
    "\n",
    "# well_name = test_df_last_30['井名']\n",
    "\n",
    "x = range(len(y_pred))\n",
    "\n",
    "plt.scatter(x, y_pred, label='Predicted')\n",
    "plt.scatter(x, y_true, label='True')\n",
    "\n",
    "plt.title('Prediction-True Comparison')\n",
    "plt.ylabel('TOC')\n",
    "plt.xlabel('Sample Number')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_true, y_pred, label='Predicted')\n",
    "plt.ylabel('Predicted TOC')\n",
    "plt.xlabel('True TOC')\n",
    "\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=2)\n",
    "plt.title('Prediction-True Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
