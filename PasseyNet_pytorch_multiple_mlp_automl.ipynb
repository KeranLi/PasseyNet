{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb34e14-49ee-47c9-b10c-e5e55b4b32b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ray\n",
    "from ray import tune\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dab87b-45ee-47d9-aa5e-1f767de59f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth/Thickness(m)</th>\n",
       "      <th>GR(API)</th>\n",
       "      <th>AC(us/m)</th>\n",
       "      <th>RT(ohm×m)</th>\n",
       "      <th>TOC(%)</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Author</th>\n",
       "      <th>Well</th>\n",
       "      <th>Area</th>\n",
       "      <th>DOI1</th>\n",
       "      <th>DOI2</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2490.000</td>\n",
       "      <td>29.06525</td>\n",
       "      <td>65.23841</td>\n",
       "      <td>78.04103</td>\n",
       "      <td>1.72428</td>\n",
       "      <td>Oil &amp; Gas Geology (Chinese Edition)/Marine Pet...</td>\n",
       "      <td>Shen et al., 2021/Nie et., 2021</td>\n",
       "      <td>N201</td>\n",
       "      <td>Changning/South Sichuan</td>\n",
       "      <td>10.11743/ogg20210109</td>\n",
       "      <td>10.3969/j.issn.1672-9854.2021.01.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2490.125</td>\n",
       "      <td>30.90459</td>\n",
       "      <td>66.23507</td>\n",
       "      <td>99.68520</td>\n",
       "      <td>1.58637</td>\n",
       "      <td>Oil &amp; Gas Geology (Chinese Edition)/Marine Pet...</td>\n",
       "      <td>Shen et al., 2021/Nie et., 2022</td>\n",
       "      <td>N201</td>\n",
       "      <td>Changning/South Sichuan</td>\n",
       "      <td>10.11743/ogg20210109</td>\n",
       "      <td>10.3969/j.issn.1672-9854.2021.01.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2490.250</td>\n",
       "      <td>33.11180</td>\n",
       "      <td>67.23173</td>\n",
       "      <td>112.66383</td>\n",
       "      <td>1.58637</td>\n",
       "      <td>Oil &amp; Gas Geology (Chinese Edition)/Marine Pet...</td>\n",
       "      <td>Shen et al., 2021/Nie et., 2023</td>\n",
       "      <td>N201</td>\n",
       "      <td>Changning/South Sichuan</td>\n",
       "      <td>10.11743/ogg20210109</td>\n",
       "      <td>10.3969/j.issn.1672-9854.2021.01.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2490.375</td>\n",
       "      <td>32.74393</td>\n",
       "      <td>68.22838</td>\n",
       "      <td>116.16438</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>Oil &amp; Gas Geology (Chinese Edition)/Marine Pet...</td>\n",
       "      <td>Shen et al., 2021/Nie et., 2024</td>\n",
       "      <td>N201</td>\n",
       "      <td>Changning/South Sichuan</td>\n",
       "      <td>10.11743/ogg20210109</td>\n",
       "      <td>10.3969/j.issn.1672-9854.2021.01.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2490.500</td>\n",
       "      <td>31.27246</td>\n",
       "      <td>67.23173</td>\n",
       "      <td>102.78249</td>\n",
       "      <td>1.86219</td>\n",
       "      <td>Oil &amp; Gas Geology (Chinese Edition)/Marine Pet...</td>\n",
       "      <td>Shen et al., 2021/Nie et., 2025</td>\n",
       "      <td>N201</td>\n",
       "      <td>Changning/South Sichuan</td>\n",
       "      <td>10.11743/ogg20210109</td>\n",
       "      <td>10.3969/j.issn.1672-9854.2021.01.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth/Thickness(m)   GR(API)  AC(us/m)  RT(ohm×m)   TOC(%)  \\\n",
       "0            2490.000  29.06525  65.23841   78.04103  1.72428   \n",
       "1            2490.125  30.90459  66.23507   99.68520  1.58637   \n",
       "2            2490.250  33.11180  67.23173  112.66383  1.58637   \n",
       "3            2490.375  32.74393  68.22838  116.16438  1.51742   \n",
       "4            2490.500  31.27246  67.23173  102.78249  1.86219   \n",
       "\n",
       "                                             Journal  \\\n",
       "0  Oil & Gas Geology (Chinese Edition)/Marine Pet...   \n",
       "1  Oil & Gas Geology (Chinese Edition)/Marine Pet...   \n",
       "2  Oil & Gas Geology (Chinese Edition)/Marine Pet...   \n",
       "3  Oil & Gas Geology (Chinese Edition)/Marine Pet...   \n",
       "4  Oil & Gas Geology (Chinese Edition)/Marine Pet...   \n",
       "\n",
       "                            Author  Well                     Area  \\\n",
       "0  Shen et al., 2021/Nie et., 2021  N201  Changning/South Sichuan   \n",
       "1  Shen et al., 2021/Nie et., 2022  N201  Changning/South Sichuan   \n",
       "2  Shen et al., 2021/Nie et., 2023  N201  Changning/South Sichuan   \n",
       "3  Shen et al., 2021/Nie et., 2024  N201  Changning/South Sichuan   \n",
       "4  Shen et al., 2021/Nie et., 2025  N201  Changning/South Sichuan   \n",
       "\n",
       "                   DOI1                                  DOI2  Unnamed: 11  \\\n",
       "0  10.11743/ogg20210109  10.3969/j.issn.1672-9854.2021.01.005          NaN   \n",
       "1  10.11743/ogg20210109  10.3969/j.issn.1672-9854.2021.01.005          NaN   \n",
       "2  10.11743/ogg20210109  10.3969/j.issn.1672-9854.2021.01.005          NaN   \n",
       "3  10.11743/ogg20210109  10.3969/j.issn.1672-9854.2021.01.005          NaN   \n",
       "4  10.11743/ogg20210109  10.3969/j.issn.1672-9854.2021.01.005          NaN   \n",
       "\n",
       "  Unnamed: 12  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3           `  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading training set into dataframe\n",
    "df = pd.read_csv('./data/TOC_WF_LMX_2K.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7229f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Depth/Thickness(m)')\n",
    "df = df.drop(columns='Journal')\n",
    "df = df.drop(columns='Author')\n",
    "df = df.drop(columns='Well')\n",
    "df = df.drop(columns='Area')\n",
    "df = df.drop(columns='DOI1')\n",
    "df = df.drop(columns='DOI2')\n",
    "df = df.drop(columns='Unnamed: 11')\n",
    "df = df.drop(columns='Unnamed: 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b94cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2554,), (2554, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is an example, taking TOC as label to predict\n",
    "label = df['TOC(%)']\n",
    "train = df.drop('TOC(%)', axis=1) # we don't need it in this project\n",
    "label.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de3e52b-c81e-4158-85fd-22df0d1edb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to min-max normalize\n",
    "def normalize(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with normalized specified features\n",
    "    \"\"\"\n",
    "    result = df.copy() # do not touch the original df\n",
    "    for feature_name in cols:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        if max_value > min_value:\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba56068-6779-492c-8e6d-433086081a50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GR(API)</th>\n",
       "      <th>AC(us/m)</th>\n",
       "      <th>RT(ohm×m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048273</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.049639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.174820</td>\n",
       "      <td>0.063547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055404</td>\n",
       "      <td>0.177998</td>\n",
       "      <td>0.071888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054756</td>\n",
       "      <td>0.181176</td>\n",
       "      <td>0.074137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052163</td>\n",
       "      <td>0.177998</td>\n",
       "      <td>0.065538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>0.185708</td>\n",
       "      <td>0.642884</td>\n",
       "      <td>0.370392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0.180394</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>0.413156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>0.191022</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>0.514045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>0.413156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>0.297669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2554 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GR(API)  AC(us/m)  RT(ohm×m)\n",
       "0     0.048273  0.171642   0.049639\n",
       "1     0.051515  0.174820   0.063547\n",
       "2     0.055404  0.177998   0.071888\n",
       "3     0.054756  0.181176   0.074137\n",
       "4     0.052163  0.177998   0.065538\n",
       "...        ...       ...        ...\n",
       "2549  0.185708  0.642884   0.370392\n",
       "2550  0.180394  0.635238   0.413156\n",
       "2551  0.191022  0.635238   0.514045\n",
       "2552  0.183051  0.635238   0.413156\n",
       "2553  0.183051  0.635238   0.297669\n",
       "\n",
       "[2554 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizing dataset\n",
    "new_train = normalize(train,train.columns)\n",
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2065e924-5158-48e4-88c2-177475cadae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.isnull().values.any()\n",
    "new_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff7d4656-eb84-49ff-8693-b471ddfd8ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test Nan and fill with mean\n",
    "for column in list(new_train.columns[ new_train.isnull().sum() > 0]):\n",
    "    mean_val = new_train[column].mean()\n",
    "    new_train[column].fillna(mean_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5516439b-836c-4fc6-8764-e2e38ab75597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = np.array(new_train)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6298a7e4-69f1-4b70-ab4d-95faf37ff799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = torch.tensor(train, dtype=torch.float32)\n",
    "label = torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f1dbdb8-33fa-4d6c-8852-ae9ac4047f51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2554]), torch.Size([2554, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37867f50-f9e6-4d88-aeba-bc82581b43dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63b318e2-6a0c-40ed-ad92-db866ec53336",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_hidden_sizes' from 'utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_hidden_sizes\n\u001b[0;32m      3\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mWellLogNet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m      4\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hyperparams):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_hidden_sizes' from 'utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "from utils.half_attenuate import HiddenSizesGenerator\n",
    "\n",
    "class WellLogNet(nn.Module):\n",
    "    def __init__(self, hyperparams={}):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fix the hyper-paremeters in the input and output layers\n",
    "\n",
    "        layers = []\n",
    "        in_size = hyperparams[\"input_dim\"]\n",
    "        out_size = hyperparams[\"output_dim\"]\n",
    "        sizes = HiddenSizeGenerator(hyperparams[\"hidden_sizes\"])\n",
    "        \n",
    "        for i, size in enumerate(sizes[:-1]):\n",
    "            layers.append(nn.Linear(in_size, size))\n",
    "            in_size = size\n",
    "        \n",
    "        layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Here, we use relu function to activate except for the last layer\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "class RONet(nn.Module):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fix the hyper-paremeters in the input and output layers\n",
    "\n",
    "        layers = []\n",
    "        in_size = hyperparams[\"input_dim\"]\n",
    "        out_size = hyperparams[\"output_dim\"]\n",
    "        sizes = HiddenSizeGenerator(hyperparams[\"hidden_sizes\"])\n",
    "\n",
    "        for i, size in enumerate(sizes[:-1]):\n",
    "            layers.append(nn.Linear(in_size, size))\n",
    "            in_size = size\n",
    "\n",
    "        layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Here, we use relu function to activate except for the last layer\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layers[-1](x)\n",
    "    \n",
    "class BiasNet(nn.Module):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fix the hyper-paremeters in the input and output layers\n",
    "\n",
    "        layers = []\n",
    "        in_size = hyperparams[\"input_dim\"]\n",
    "        out_size = hyperparams[\"output_dim\"]\n",
    "        sizes = HiddenSizeGenerator(hyperparams[\"hidden_sizes\"])\n",
    "\n",
    "        for i, size in enumerate(sizes[:-1]):\n",
    "            layers.append(nn.Linear(in_size, size))\n",
    "            in_size = size\n",
    "        \n",
    "        layers.append(nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Here, we use relu function to activate except for the last layer\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "class PasseyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PasseyNet, self).__init__()\n",
    "        self.well_log_net = WellLogNet()\n",
    "        self.ro_net = RONet()\n",
    "        self.bias_net = BiasNet()\n",
    "\n",
    "    def set_well_log_net_hyperparams(self, hp):\n",
    "        self.well_log_net.hyperparams = hp\n",
    "    \n",
    "    def set_ro_net_hyperparams(self, hp):\n",
    "        self.ro_net.hyperparams = hp\n",
    "    \n",
    "    def set_bias_net_hyperparams(self, hp):\n",
    "        self.bias_net.hyperparams = hp\n",
    "\n",
    "    def forward(self, x):\n",
    "        well_log_matrix = self.well_log_net(x)\n",
    "        ro_matrix = self.ro_net(x)\n",
    "        bias_matrix = self.bias_net(x)\n",
    "        \n",
    "        output = torch.matmul(torch.matmul(x, well_log_matrix.T), \n",
    "                              torch.pow(10.0, ro_matrix)) + bias_matrix\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee21ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters for search in the Net \n",
    "config = {\n",
    "  \"well_log_net\": {\n",
    "      \"input_dim\": 3,\n",
    "     \"hidden_sizes\": tune.choice([256, 512, 1024]),\n",
    "     \"output_dim\": 3 \n",
    "  },\n",
    "  \n",
    "  \"ro_net\": {\n",
    "      \"input_dim\": 3,\n",
    "     \"hidden_sizes\": tune.choice([256, 512, 1024]),\n",
    "     \"output_dim\": 1\n",
    "  },\n",
    "  \n",
    "  \"bias_net\": {\n",
    "      \"input_dim\": 3,\n",
    "     \"hidden_sizes\": tune.choice([256, 512, 1024]),\n",
    "     \"output_dim\": 1\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a86486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 20:58:37,065\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-08-08 20:58:39,302\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-08 20:58:49</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.26        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.1/15.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/12 CPUs, 1.0/1 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_4b5ec_00000</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">     bias_net/hidden_size\n",
       "s</th><th style=\"text-align: right;\">  ro_net/hidden_sizes</th><th style=\"text-align: right;\">     well_log_net/hidden_\n",
       "sizes</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_4b5ec_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\"> 512</td></tr>\n",
       "<tr><td>train_model_4b5ec_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\"> 256</td></tr>\n",
       "<tr><td>train_model_4b5ec_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">1024</td></tr>\n",
       "<tr><td>train_model_4b5ec_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">1024</td></tr>\n",
       "<tr><td>train_model_4b5ec_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\"> 256</td></tr>\n",
       "<tr><td>train_model_4b5ec_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                 1024</td><td style=\"text-align: right;\">1024</td></tr>\n",
       "<tr><td>train_model_4b5ec_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\"> 256</td></tr>\n",
       "<tr><td>train_model_4b5ec_00008</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\"> 512</td></tr>\n",
       "<tr><td>train_model_4b5ec_00009</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\"> 512</td></tr>\n",
       "<tr><td>train_model_4b5ec_00000</td><td>ERROR   </td><td>127.0.0.1:4656</td><td style=\"text-align: right;\">1024</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\"> 512</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 20:58:44,212\tERROR tune_controller.py:911 -- Trial task failed for trial train_model_4b5ec_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\_private\\worker.py\", line 2493, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4656, ip=127.0.0.1, actor_id=c56cc040c0ef8cd94665089801000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 375, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 349, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"f:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 666, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_19940\\1587974121.py\", line 14, in train_model\n",
      "TypeError: __init__() missing 1 required positional argument: 'hyperparams'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_4b5ec_00000</td></tr>\n",
       "<tr><td>train_model_4b5ec_00001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=4656)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/Administrator/ray_results/train_model_2023-08-08_20-58-39/train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39/error.pkl', which is outside base dir 'C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(train_model pid=4656)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/Administrator/ray_results/train_model_2023-08-08_20-58-39/train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39/error.pkl', which is outside base dir 'C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(train_model pid=4656)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/Administrator/ray_results/train_model_2023-08-08_20-58-39/train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39/error.pkl', which is outside base dir 'C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(train_model pid=4656)\u001b[0m Could not upload checkpoint to c://\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00000_0_hidden_sizes=1024,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39 even after 3 retries.Please check if the credentials expired and that the remote filesystem is supported. For large checkpoints or artifacts, consider increasing `SyncConfig(sync_timeout)` (current value: 1800 seconds).\n",
      "\u001b[2m\u001b[36m(train_model pid=15796)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/Administrator/ray_results/train_model_2023-08-08_20-58-39/train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39/error.pkl', which is outside base dir 'C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(train_model pid=15796)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/Administrator/ray_results/train_model_2023-08-08_20-58-39/train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39/error.pkl', which is outside base dir 'C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(train_model pid=15796)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/Administrator/ray_results/train_model_2023-08-08_20-58-39/train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39/error.pkl', which is outside base dir 'C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(train_model pid=15796)\u001b[0m Could not upload checkpoint to c://\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\train_model_4b5ec_00001_1_hidden_sizes=512,hidden_sizes=512,hidden_sizes=512_2023-08-08_20-58-39 even after 3 retries.Please check if the credentials expired and that the remote filesystem is supported. For large checkpoints or artifacts, consider increasing `SyncConfig(sync_timeout)` (current value: 1800 seconds).\n",
      "2023-08-08 20:58:58,001\tERROR tune.py:1144 -- Trials did not complete: [train_model_4b5ec_00000, train_model_4b5ec_00001]\n",
      "2023-08-08 20:58:58,002\tINFO tune.py:1148 -- Total run time: 18.70 seconds (15.36 seconds for the tuning loop).\n",
      "2023-08-08 20:58:58,003\tWARNING tune.py:1163 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\experiment_state-2023-08-08_20-58-39.json` must either be a path to an experiment checkpoint file, or a directory containing an experiment checkpoint file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m ray\u001b[39m.\u001b[39mshutdown()\n\u001b[0;32m     94\u001b[0m ray\u001b[39m.\u001b[39minit(num_gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m analysis \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m     97\u001b[0m     train_model,\n\u001b[0;32m     98\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     99\u001b[0m     num_samples\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \u001b[39m# Number of tray\u001b[39;49;00m\n\u001b[0;32m    100\u001b[0m     metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    101\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    102\u001b[0m     resources_per_trial\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1\u001b[39;49m}  \n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[39m# Best config   \u001b[39;00m\n\u001b[0;32m    106\u001b[0m best_config \u001b[39m=\u001b[39m analysis\u001b[39m.\u001b[39mget_best_config()\n",
      "File \u001b[1;32mf:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\tune\\tune.py:1167\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, checkpoint_keep_all_ranks, checkpoint_upload_from_workers, trial_executor, local_dir, _experiment_checkpoint_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1163\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m   1164\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExperiment has been interrupted, but the most recent state was \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1165\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msaved.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mResume experiment with: \u001b[39m\u001b[39m{\u001b[39;00mrestore_entrypoint\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1166\u001b[0m         )\n\u001b[1;32m-> 1167\u001b[0m ea \u001b[39m=\u001b[39m ExperimentAnalysis(\n\u001b[0;32m   1168\u001b[0m     experiment_checkpoint,\n\u001b[0;32m   1169\u001b[0m     trials\u001b[39m=\u001b[39;49mall_trials,\n\u001b[0;32m   1170\u001b[0m     default_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1171\u001b[0m     default_mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   1172\u001b[0m     remote_storage_path\u001b[39m=\u001b[39;49mremote_path,\n\u001b[0;32m   1173\u001b[0m )\n\u001b[0;32m   1175\u001b[0m \u001b[39mreturn\u001b[39;00m ea\n",
      "File \u001b[1;32mf:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:114\u001b[0m, in \u001b[0;36mExperimentAnalysis.__init__\u001b[1;34m(self, experiment_checkpoint_path, trials, default_metric, default_mode, remote_storage_path, sync_config)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experiment_states \u001b[39m=\u001b[39m []\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoints_and_paths: List[Tuple[\u001b[39mdict\u001b[39m, os\u001b[39m.\u001b[39mPathLike]] \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_checkpoints(experiment_checkpoint_path)\n\u001b[0;32m    115\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoints_and_paths\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials \u001b[39m=\u001b[39m trials\n",
      "File \u001b[1;32mf:\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:196\u001b[0m, in \u001b[0;36mExperimentAnalysis._load_checkpoints\u001b[1;34m(self, experiment_checkpoint_path)\u001b[0m\n\u001b[0;32m    194\u001b[0m latest_checkpoints \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_latest_checkpoint(experiment_checkpoint_path)\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m latest_checkpoints:\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mexperiment_checkpoint_path\u001b[39m}\u001b[39;00m\u001b[39m` must either be a path to an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexperiment checkpoint file, or a directory containing an experiment \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcheckpoint file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m \u001b[39m# Collect all checkpoints and their directory paths.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39m# These are used to infer the `local_dir` from the checkpoints\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m# in case the experiment folder had been moved from its original\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m# location (e.g. from a ray cluster to a GCS/S3 bucket or to local disk).\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_checkpoints_from_latest(latest_checkpoints)\n",
      "\u001b[1;31mValueError\u001b[0m: `C:\\Users\\Administrator\\ray_results\\train_model_2023-08-08_20-58-39\\experiment_state-2023-08-08_20-58-39.json` must either be a path to an experiment checkpoint file, or a directory containing an experiment checkpoint file."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error \n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Define the NAS by ray\n",
    "def train_model(config):\n",
    "\n",
    "    # Initializing sub-models by config\n",
    "\n",
    "    well_log_net = WellLogNet()  \n",
    "    ro_net = RONet()\n",
    "    bias_net = BiasNet()\n",
    "\n",
    "    model = PasseyNet() # Initializing defaultly\n",
    "    model.set_well_log_net_hyperparams()\n",
    "    model.set_ro_net_hyperparams()\n",
    "    model.set_bias_net_hyperparams()\n",
    "    model.to(device)\n",
    "\n",
    "    train = train.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    # Initializing optimizer and loss functions\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    score = -val_mse(model)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Store loss、mae、mse、R2、mape\n",
    "loss_list = []\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "r2_adjust_list = []\n",
    "mape_list = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) # 5-fold\n",
    "\n",
    "    for fold ,(train_idx, val_idx) in enumerate(kf.split(train)):\n",
    "\n",
    "        # Dividing training and validating datasets\n",
    "        train_x, train_y = train[train_idx], label[train_idx]\n",
    "        val_x, val_y = train[val_idx], label[val_idx]\n",
    "\n",
    "        for epoch in range(100):\n",
    "\n",
    "            output = model(train) # Training\n",
    "            output = output.cpu() # Return output to CPU\n",
    "            label = label.cpu() # Return label to CPU\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            optimizer.zero_grad()   \n",
    "            loss.backward()        \n",
    "            optimizer.step()\n",
    "\n",
    "            # Validating\n",
    "            with torch.no_grad():\n",
    "                val_output = model(val_x)\n",
    "                val_output = val_output.cpu()\n",
    "                val_y = val_y.cpu()\n",
    "                val_loss = criterion(val_output, val_y)\n",
    "\n",
    "                val_pred = val_output.detach().numpy()\n",
    "                val_true = val_y.detach().numpy()\n",
    "\n",
    "                val_mae = mean_absolute_error(val_true, val_pred)\n",
    "                val_mse = mean_squared_error(val_true, val_pred)\n",
    "\n",
    "                val_r2 = r2_score(val_true, val_pred)\n",
    "                val_mape = mean_absolute_percentage_error(val_true, val_pred)\n",
    "\n",
    "                val_adjust_r2 = 1-((1-val_r2)*(len(val_x)-1))/(len(val_x)-6-1)\n",
    "                \n",
    "                # 打印结果  \n",
    "                # print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}, R2: {val_r2:.4f}, MAE: {val_mae:.4f}, MSE: {val_mse:.4f}, MAPE: {val_mape:.4f}')\n",
    "        \n",
    "            # 存储loss、mae和mse\n",
    "            loss_list.append(val_loss.item())\n",
    "            mae_list.append(val_mae)\n",
    "            mse_list.append(val_mse)\n",
    "            r2_list.append(val_r2)\n",
    "            r2_adjust_list.append(val_adjust_r2)\n",
    "            mae_list.append(val_mape)\n",
    "\n",
    "# Run tune\n",
    "ray.shutdown()\n",
    "ray.init(num_gpus=1)\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=config,\n",
    "    num_samples=10, # Number of tray\n",
    "    metric=\"score\",\n",
    "    mode=\"max\",\n",
    "    resources_per_trial={\"gpu\": 1}  \n",
    ")\n",
    "\n",
    "# Best config   \n",
    "best_config = analysis.get_best_config()\n",
    "\n",
    "# Generate model by the best config\n",
    "well_log_net = WellLogNet(best_config[\"well_log_net\"])\n",
    "ro_net = RONet(best_config[\"ro_net\"])\n",
    "bias_net = BiasNet(best_config[\"bias_net\"])\n",
    "best_model = PasseyNet(well_log_net, ro_net, bias_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 5-fold training results        \n",
    "plt.plot(loss_list)\n",
    "plt.title('Five-Fold Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# 绘制MAE、MSE、MAPE curves\n",
    "plt.plot(mae_list, label='MAE')\n",
    "plt.plot(mse_list, label='MSE')\n",
    "plt.plot(mae_list, label='MAE')\n",
    "plt.title('MAE, MSE, MAPE Curve')  \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot R2、R2_adjust curves\n",
    "plt.plot(r2_list, label='R2')\n",
    "plt.plot(r2_adjust_list, label='R2_adjust')\n",
    "plt.title('R2 & Adjusted R2 Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training set into dataframe\n",
    "test_df = pd.read_csv('./data/TOC_WF_LMX.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns='Depth/Thickness(m)')\n",
    "test_df = test_df.drop(columns='Journal')\n",
    "test_df = test_df.drop(columns='Author')\n",
    "test_df = test_df.drop(columns='Well')\n",
    "test_df = test_df.drop(columns='Area')\n",
    "test_df = test_df.drop(columns='DOI1')\n",
    "test_df = test_df.drop(columns='DOI2')\n",
    "test_df = test_df.drop(columns='Unnamed: 11')\n",
    "test_df = test_df.drop(columns='Unnamed: 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09aef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_last_30 = test_df.tail(30)\n",
    "test_df_last_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ec004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example, taking TOC as label to predict\n",
    "test_label = test_df_last_30['TOC(%)']\n",
    "test_train = test_df_last_30.drop('TOC(%)', axis=1) # we don't need it in this project\n",
    "test_label.shape, test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train = test_train.drop(columns='井名')\n",
    "# test_train = test_train.drop(columns='Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b135ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing dataset\n",
    "normalized_test_train = normalize(test_train, test_train.columns)\n",
    "normalized_test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41110f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Nan and fill with mean\n",
    "for column in list(normalized_test_train.columns[ normalized_test_train.isnull().sum() > 0]):\n",
    "    mean_val = normalized_test_train[column].mean()\n",
    "    normalized_test_train[column].fillna(mean_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ec0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要传入Tensor \n",
    "X_test = normalized_test_train.values # 转为numpy数组\n",
    "X_test = torch.Tensor(X_test).to(device) # 转为Tensor\n",
    "\n",
    "\n",
    "# 切换到训练模式\n",
    "model.train() \n",
    "\n",
    "# 预测值 \n",
    "y_pred = model(X_test)\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "# 真实值\n",
    "y_true = test_label \n",
    "\n",
    "# 残差 \n",
    "y_true = y_true.ravel()  \n",
    "y_pred = y_pred.ravel()\n",
    "resid = y_true - y_pred\n",
    "\n",
    "# 绘图\n",
    "plt.hist(resid, bins=20)\n",
    "plt.title('Residuals Histogram')\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 均值和标准差\n",
    "mean = resid.mean()\n",
    "stddev = resid.std()\n",
    "\n",
    "# 绘制竖直线\n",
    "plt.axvline(mean, color='r')\n",
    "plt.axvline(mean + 2*stddev, color='r', linestyle='--')\n",
    "plt.axvline(mean - 2*stddev, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测值实际值差距图\n",
    "\n",
    "# well_name = test_df_last_30['井名']\n",
    "\n",
    "x = range(len(y_pred))\n",
    "\n",
    "plt.scatter(x, y_pred, label='Predicted')\n",
    "plt.scatter(x, y_true, label='True')\n",
    "\n",
    "plt.title('Prediction-True Comparison')\n",
    "plt.ylabel('TOC')\n",
    "plt.xlabel('Sample Number')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_true, y_pred, label='Predicted')\n",
    "plt.ylabel('Predicted TOC')\n",
    "plt.xlabel('True TOC')\n",
    "\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=2)\n",
    "plt.title('Prediction-True Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
